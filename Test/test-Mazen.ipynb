{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b058ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to PSQLAPPEG297-01...\n",
      "‚úÖ Success! Table 'ThermalReadings' has been cleared.\n"
     ]
    }
   ],
   "source": [
    "##################################### DELETE ALL DATA FROM TABLE ####################\n",
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DB_SERVER = \"PSQLAPPEG297-01\"\n",
    "DB_NAME = \"Flir\"\n",
    "DB_USER = \"Flir\"\n",
    "DB_PASS = \"Prom@2025\"\n",
    "DB_TABLE = \"ThermalReadings\"\n",
    "\n",
    "def delete_table_data():\n",
    "    # 1. Safety Check\n",
    "    confirm = input(f\"‚ö†Ô∏è ARE YOU SURE you want to delete ALL rows from '{DB_TABLE}'? (Type 'yes' to confirm): \")\n",
    "    if confirm.lower() != \"yes\":\n",
    "        print(\"Action cancelled.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        print(f\"Connecting to {DB_SERVER}...\")\n",
    "        \n",
    "        # 2. Encode Password & Connect\n",
    "        encoded_pass = quote_plus(DB_PASS)\n",
    "        db_url = f\"mssql+pyodbc://{DB_USER}:{encoded_pass}@{DB_SERVER}/{DB_NAME}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        engine = create_engine(db_url)\n",
    "\n",
    "        # 3. Execute Delete\n",
    "        with engine.connect() as conn:\n",
    "            # Using 'DELETE' instead of 'TRUNCATE' is safer regarding permissions\n",
    "            # sql = text(f\"DELETE FROM {DB_TABLE} where Filename like 'FLIR0058.jpg'\")\n",
    "            sql = text(f\"DELETE FROM {DB_TABLE}\")\n",
    "            result = conn.execute(sql)\n",
    "            conn.commit()\n",
    "            print(f\"‚úÖ Success! Table '{DB_TABLE}' has been cleared.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error deleting data: {e}\")\n",
    "\n",
    "# Run the delete function\n",
    "delete_table_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448c122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to PSQLAPPEG297-01...\n",
      "Preparing to insert 20 rows...\n",
      "‚úÖ Success! Mock data inserted.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote_plus\n",
    "import io\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DB_SERVER = \"PSQLAPPEG297-01\"\n",
    "DB_NAME = \"Flir\"\n",
    "DB_USER = \"Flir\"\n",
    "DB_PASS = \"Prom@2025\"\n",
    "DB_TABLE = \"ThermalReadings\"\n",
    "\n",
    "# Year to generate data for\n",
    "START_DATE = datetime(2025, 1, 1)\n",
    "END_DATE = datetime(2025, 12, 31)\n",
    "\n",
    "# --- ASSET DEFINITIONS ---\n",
    "# Format: (Section, MachineID, AssetName, AssetCode, Trend_Type)\n",
    "# Trend Types: 'stable', 'critical_spike', 'steady_warming', 'steady_cooling'\n",
    "ASSETS = [\n",
    "    {\"code\": \"TestCodeBuilding-01\", \"name\": \"TestName-build\", \"trend\": \"stable\", \"base_temp\": 35},\n",
    "    {\"code\": \"TestCodeCuring-01\",   \"name\": \"TestName-curing\", \"trend\": \"critical_spike\", \"base_temp\": 50},\n",
    "    {\"code\": \"TestCodeMixer-01\",    \"name\": \"TestName-mixer\",  \"trend\": \"steady_warming\", \"base_temp\": 40},\n",
    "    {\"code\": \"TestCodeSemi-01\",     \"name\": \"TestName-semi\",   \"trend\": \"steady_cooling\", \"base_temp\": 80},\n",
    "]\n",
    "\n",
    "def get_db_engine():\n",
    "    encoded_pass = quote_plus(DB_PASS)\n",
    "    db_url = f\"mssql+pyodbc://{DB_USER}:{encoded_pass}@{DB_SERVER}/{DB_NAME}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "    return create_engine(db_url, fast_executemany=True)\n",
    "\n",
    "def generate_dummy_image(temp_val):\n",
    "    \"\"\"Generates a tiny 10x10 heat map image string to prevent broken image icons.\"\"\"\n",
    "    data = np.random.rand(10, 10) * temp_val # Random noise scaled by temp\n",
    "    buffer = io.BytesIO()\n",
    "    plt.imsave(buffer, data, cmap='inferno', format='jpeg')\n",
    "    buffer.seek(0)\n",
    "    return f\"data:image/jpeg;base64,{base64.b64encode(buffer.getvalue()).decode('utf-8')}\"\n",
    "\n",
    "def calculate_temp(asset, date_obj):\n",
    "    \"\"\"Calculates specific temperature based on the asset's assigned trend.\"\"\"\n",
    "    \n",
    "    # 1. Seasonality (Hotter in July/Aug)\n",
    "    day_of_year = date_obj.timetuple().tm_yday\n",
    "    season_factor = 1 + (0.15 * np.sin((day_of_year - 100) / 365 * 2 * np.pi)) # +/- 15% Swing\n",
    "    \n",
    "    base = asset['base_temp']\n",
    "    trend = asset['trend']\n",
    "    noise = random.uniform(-1.5, 1.5) # Natural variation\n",
    "\n",
    "    final_temp = base\n",
    "    \n",
    "    if trend == 'stable':\n",
    "        final_temp = (base * season_factor) + noise\n",
    "        \n",
    "    elif trend == 'critical_spike':\n",
    "        # Normal most of the year, but SPIKES huge in July (Days 180-210)\n",
    "        if 180 < day_of_year < 210:\n",
    "            final_temp = 75 + random.uniform(0, 5) # Trigger Critical (>70)\n",
    "        else:\n",
    "            final_temp = (base * season_factor) + noise\n",
    "\n",
    "    elif trend == 'steady_warming':\n",
    "        # Increases by ~2 degrees every month\n",
    "        month_idx = date_obj.month\n",
    "        increase = month_idx * 2.0 \n",
    "        final_temp = base + increase + noise\n",
    "\n",
    "    elif trend == 'steady_cooling':\n",
    "        # Decreases by ~2 degrees every month\n",
    "        month_idx = date_obj.month\n",
    "        decrease = month_idx * 2.5\n",
    "        final_temp = base - decrease + noise\n",
    "\n",
    "    return round(final_temp, 1)\n",
    "\n",
    "def generate_mock_weather(date_obj):\n",
    "    \"\"\"Simple mock weather: Cold in Jan, Hot in Aug.\"\"\"\n",
    "    month = date_obj.month\n",
    "    if month in [12, 1, 2]: return round(random.uniform(10, 15), 1)\n",
    "    if month in [3, 4, 11]: return round(random.uniform(16, 22), 1)\n",
    "    if month in [5, 10]:    return round(random.uniform(23, 27), 1)\n",
    "    return round(random.uniform(28, 35), 1) # Summer\n",
    "\n",
    "def run_mock_generator():\n",
    "    print(f\"üöÄ Generating Mock Data for year {START_DATE.year}...\")\n",
    "    \n",
    "    engine = get_db_engine()\n",
    "    rows = []\n",
    "    \n",
    "    # Iterate week by week for 1 year\n",
    "    current_date = START_DATE\n",
    "    while current_date <= END_DATE:\n",
    "        \n",
    "        week_str = current_date.strftime(\"%Y-%W\")\n",
    "        print(f\"   Processing Week: {week_str}...\", end='\\r')\n",
    "\n",
    "        for asset in ASSETS:\n",
    "            # Randomize the exact time (9 AM to 2 PM)\n",
    "            hour = random.randint(9, 14)\n",
    "            minute = random.randint(0, 59)\n",
    "            timestamp = current_date.replace(hour=hour, minute=minute)\n",
    "            \n",
    "            # DB Timestamp (UTC, so subtract 2 hours from 'Local' mock time)\n",
    "            db_timestamp = timestamp - timedelta(hours=2)\n",
    "            ts_str = db_timestamp.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            # Calculate Temps\n",
    "            center_temp = calculate_temp(asset, timestamp)\n",
    "            max_temp = center_temp + random.uniform(2, 5)\n",
    "            min_temp = center_temp - random.uniform(2, 5)\n",
    "            avg_temp = center_temp - random.uniform(0, 1)\n",
    "            \n",
    "            row = {\n",
    "                \"Timestamp\": ts_str,\n",
    "                \"Filename\": f\"MOCK_{asset['code']}_{timestamp.strftime('%Y%m%d')}.jpg\",\n",
    "                \"Camera_Serial\": 999999,\n",
    "                \"Asset_Name\": asset['code'], # Linking to 'Asset Code' column\n",
    "                \"Max_Temp_C\": round(max_temp, 1),\n",
    "                \"Min_Temp_C\": round(min_temp, 1),\n",
    "                \"Center_Temp_C\": center_temp,\n",
    "                \"Avg_Temp_C\": round(avg_temp, 1),\n",
    "                \"Delta_Temp_C\": round(max_temp - min_temp, 1),\n",
    "                \"Emissivity\": 0.95,\n",
    "                \"Distance\": 2.0,\n",
    "                \"weather_temp\": generate_mock_weather(timestamp),\n",
    "                \"Image_Base64\": generate_dummy_image(center_temp) \n",
    "            }\n",
    "            rows.append(row)\n",
    "        \n",
    "        # Advance by ~7 days (weekly scans)\n",
    "        current_date += timedelta(days=7)\n",
    "\n",
    "    print(f\"\\nüì¶ Inserting {len(rows)} rows into database...\")\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    try:\n",
    "        df.to_sql(DB_TABLE, engine, if_exists='append', index=False)\n",
    "        print(\"‚úÖ Success! Database populated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inserting data: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_mock_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38726b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Processing: '12-Jan-26 02:47 PM'\n",
      "   -> Date: 2026-01-12 | Hour Index: 14\n",
      "‚úÖ Temperature at 12-Jan-26 02:47 PM: 16.9¬∞C\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# --- CONFIG ---\n",
    "ALEX_LAT = 31.2001\n",
    "ALEX_LON = 29.9187\n",
    "\n",
    "def get_weather_for_string(time_str):\n",
    "    \"\"\"\n",
    "    Parses a string like \"21-Jan-26 11:43 AM\" and fetches the weather\n",
    "    for that specific date and hour.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Parse the string into a datetime object\n",
    "        # %d=Day, %b=Month(Jan), %y=Year(2-digit), %I=12hr, %M=Min, %p=AM/PM\n",
    "        dt_obj = datetime.strptime(time_str, \"%d-%b-%y %I:%M %p\")\n",
    "        \n",
    "        # 2. Extract Date and Hour for the API\n",
    "        date_api_format = dt_obj.strftime(\"%Y-%m-%d\")\n",
    "        hour_idx = dt_obj.hour  # 11:43 AM becomes index 11\n",
    "        \n",
    "        print(f\"üîé Processing: '{time_str}'\")\n",
    "        print(f\"   -> Date: {date_api_format} | Hour Index: {hour_idx}\")\n",
    "\n",
    "        # 3. Setup API Request\n",
    "        url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "        params = {\n",
    "            \"latitude\": ALEX_LAT,\n",
    "            \"longitude\": ALEX_LON,\n",
    "            \"hourly\": \"temperature_2m\",\n",
    "            \"start_date\": date_api_format,\n",
    "            \"end_date\": date_api_format,\n",
    "            \"timezone\": \"auto\"\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params, timeout=5)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"hourly\" in data and \"temperature_2m\" in data[\"hourly\"]:\n",
    "                temps = data[\"hourly\"][\"temperature_2m\"]\n",
    "                \n",
    "                # Check if the hour exists in the returned data\n",
    "                if 0 <= hour_idx < len(temps):\n",
    "                    temp = temps[hour_idx]\n",
    "                    print(f\"‚úÖ Temperature at {time_str}: {temp}¬∞C\")\n",
    "                    return temp\n",
    "                else:\n",
    "                    print(\"‚ùå Hour not found in API response.\")\n",
    "            else:\n",
    "                print(\"‚ùå 'hourly' data missing from response.\")\n",
    "        else:\n",
    "            print(f\"‚ùå API returned status: {response.status_code}\")\n",
    "            \n",
    "    except ValueError as e:\n",
    "        print(f\"‚ùå Date Format Error. Make sure it matches 'DD-Mon-YY HH:MM AM/PM'.\\nDetails: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- PUT YOUR TIME HERE ---\n",
    "    target_time = \"12-Jan-26 02:47 PM\"\n",
    "    \n",
    "    get_weather_for_string(target_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6afd2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.3\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_alexandria_weather(dt_obj):\n",
    "    \"\"\"\n",
    "    Fetches the temperature in Alexandria for the specific hour (No Interpolation).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date_str = dt_obj.strftime(\"%Y-%m-%d\")\n",
    "        hour_idx = dt_obj.hour  # e.g., 11:43 -> 11\n",
    "        \n",
    "        url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "        params = {\n",
    "            \"latitude\": ALEX_LAT,\n",
    "            \"longitude\": ALEX_LON,\n",
    "            \"hourly\": \"temperature_2m\",\n",
    "            \"start_date\": date_str,\n",
    "            \"end_date\": date_str,\n",
    "            \"timezone\": \"auto\"\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params, timeout=3)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"hourly\" in data and \"temperature_2m\" in data[\"hourly\"]:\n",
    "                temps = data[\"hourly\"][\"temperature_2m\"]\n",
    "                \n",
    "                # Directly grab the temp for this hour index\n",
    "                if 0 <= hour_idx < len(temps):\n",
    "                    return float(temps[hour_idx])\n",
    "                    \n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ö†Ô∏è Weather API Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "print(get_alexandria_weather(datetime.strptime(\"18-Jan-26 9:54 AM\", \"%d-%b-%y %I:%M %p\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69706071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Weather Fix from 2026-01-12 00:00:00 to 2026-01-21 23:59:59...\n",
      "üìã Found 65 records. Processing...\n",
      "   üåç Fetching API data for: 2026-01-12 Hour: 14...\n",
      "   üåç Fetching API data for: 2026-01-12 Hour: 15...\n",
      "   üåç Fetching API data for: 2026-01-18 Hour: 9...\n",
      "   üåç Fetching API data for: 2026-01-20 Hour: 11...\n",
      "   üåç Fetching API data for: 2026-01-21 Hour: 9...\n",
      "   üåç Fetching API data for: 2026-01-18 Hour: 10...\n",
      "üéâ Success! Updated 65 records.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# --- CONFIG ---\n",
    "DB_SERVER = \"PSQLAPPEG297-01\"\n",
    "DB_NAME = \"Flir\"\n",
    "DB_USER = \"Flir\"\n",
    "DB_PASS = \"Prom@2025\"\n",
    "DB_TABLE = \"ThermalReadings\"\n",
    "\n",
    "# --- TIME RANGE TO FIX (Inclusive) ---\n",
    "FIX_START_DATE = \"2026-01-12 00:00:00\"\n",
    "FIX_END_DATE   = \"2026-01-21 23:59:59\"\n",
    "\n",
    "# Location\n",
    "ALEX_LAT = 31.2001\n",
    "ALEX_LON = 29.9187\n",
    "\n",
    "# Cache to avoid spamming the API (Key: \"YYYY-MM-DD-HH\", Value: Temp)\n",
    "weather_cache = {}\n",
    "\n",
    "def get_alexandria_weather_cached(dt_obj):\n",
    "    \"\"\"\n",
    "    Fetches weather for the specific hour.\n",
    "    Checks cache first to speed up processing.\n",
    "    \"\"\"\n",
    "    # Create a unique key for this hour (e.g., \"2026-01-21-09\")\n",
    "    cache_key = dt_obj.strftime(\"%Y-%m-%d-%H\")\n",
    "    \n",
    "    if cache_key in weather_cache:\n",
    "        return weather_cache[cache_key]\n",
    "\n",
    "    # --- API CALL ---\n",
    "    try:\n",
    "        date_str = dt_obj.strftime(\"%Y-%m-%d\")\n",
    "        hour_idx = dt_obj.hour\n",
    "        \n",
    "        print(f\"   üåç Fetching API data for: {date_str} Hour: {hour_idx}...\")\n",
    "        \n",
    "        url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "        params = {\n",
    "            \"latitude\": ALEX_LAT,\n",
    "            \"longitude\": ALEX_LON,\n",
    "            \"hourly\": \"temperature_2m\",\n",
    "            \"start_date\": date_str,\n",
    "            \"end_date\": date_str,\n",
    "            \"timezone\": \"auto\"\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params, timeout=5)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"hourly\" in data and \"temperature_2m\" in data[\"hourly\"]:\n",
    "                temps = data[\"hourly\"][\"temperature_2m\"]\n",
    "                if 0 <= hour_idx < len(temps):\n",
    "                    temp = float(temps[hour_idx])\n",
    "                    # Save to cache\n",
    "                    weather_cache[cache_key] = temp\n",
    "                    return temp\n",
    "        \n",
    "        print(f\"   ‚ùå Weather data unavailable for {cache_key}\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå API Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_weather_fix():\n",
    "    print(f\"üöÄ Starting Weather Fix from {FIX_START_DATE} to {FIX_END_DATE}...\")\n",
    "    \n",
    "    encoded_pass = quote_plus(DB_PASS)\n",
    "    db_url = f\"mssql+pyodbc://{DB_USER}:{encoded_pass}@{DB_SERVER}/{DB_NAME}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "    engine = create_engine(db_url)\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            # 1. Get the list of files to update\n",
    "            select_query = text(f\"\"\"\n",
    "                SELECT Filename, Timestamp \n",
    "                FROM {DB_TABLE} \n",
    "                WHERE Timestamp >= :start AND Timestamp <= :end\n",
    "            \"\"\")\n",
    "            \n",
    "            result = conn.execute(select_query, {\"start\": FIX_START_DATE, \"end\": FIX_END_DATE})\n",
    "            rows = result.fetchall()\n",
    "            \n",
    "            if not rows:\n",
    "                print(\"‚úÖ No records found in this range.\")\n",
    "                return\n",
    "\n",
    "            print(f\"üìã Found {len(rows)} records. Processing...\")\n",
    "\n",
    "            updated_count = 0\n",
    "            \n",
    "            # 2. Iterate and Update\n",
    "            for row in rows:\n",
    "                filename = row[0]\n",
    "                timestamp = row[1] # This is already a datetime object from SQL\n",
    "\n",
    "                # Get weather (Cached version)\n",
    "                new_temp = get_alexandria_weather_cached(timestamp)\n",
    "\n",
    "                if new_temp is not None:\n",
    "                    update_query = text(f\"\"\"\n",
    "                        UPDATE {DB_TABLE} \n",
    "                        SET weather_temp = :temp \n",
    "                        WHERE Filename = :fname\n",
    "                    \"\"\")\n",
    "                    conn.execute(update_query, {\"temp\": new_temp, \"fname\": filename})\n",
    "                    updated_count += 1\n",
    "            \n",
    "            conn.commit()\n",
    "            print(f\"üéâ Success! Updated {updated_count} records.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Database Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_weather_fix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "871cdc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  WARNING: You are about to DELETE 4 records.\n",
      "   üìÖ Range: 2025-01-1 00:00:00  -->  2026-01-21 23:59:59\n",
      "üóëÔ∏è  Success: 4 records deleted.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# --- CONFIG ---\n",
    "DB_SERVER = \"PSQLAPPEG297-01\"\n",
    "DB_NAME = \"Flir\"\n",
    "DB_USER = \"Flir\"\n",
    "DB_PASS = \"Prom@2025\"\n",
    "DB_TABLE = \"ThermalReadings\"\n",
    "\n",
    "# --- DATE RANGE TO DELETE (Inclusive) ---\n",
    "DELETE_FROM_DATE = \"2025-01-1 00:00:00\"\n",
    "DELETE_END_DATE  = \"2026-01-21 23:59:59\"\n",
    "\n",
    "def delete_range_records():\n",
    "    # 1. Setup Connection\n",
    "    encoded_pass = quote_plus(DB_PASS)\n",
    "    db_url = f\"mssql+pyodbc://{DB_USER}:{encoded_pass}@{DB_SERVER}/{DB_NAME}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "    engine = create_engine(db_url)\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            # 2. Check how many records match the range\n",
    "            count_query = text(f\"\"\"\n",
    "                SELECT COUNT(*) FROM {DB_TABLE} \n",
    "                WHERE Timestamp >= :start_date AND Timestamp <= :end_date\n",
    "            \"\"\")\n",
    "            \n",
    "            params = {\"start_date\": DELETE_FROM_DATE, \"end_date\": DELETE_END_DATE}\n",
    "            result = conn.execute(count_query, params).scalar()\n",
    "\n",
    "            if result == 0:\n",
    "                print(f\"‚úÖ No records found between {DELETE_FROM_DATE} and {DELETE_END_DATE}.\")\n",
    "                return\n",
    "\n",
    "            print(f\"‚ö†Ô∏è  WARNING: You are about to DELETE {result} records.\")\n",
    "            print(f\"   üìÖ Range: {DELETE_FROM_DATE}  -->  {DELETE_END_DATE}\")\n",
    "            confirm = input(\"Type 'DELETE' to confirm: \")\n",
    "\n",
    "            if confirm == \"DELETE\":\n",
    "                # 3. Perform Deletion\n",
    "                delete_query = text(f\"\"\"\n",
    "                    DELETE FROM {DB_TABLE} \n",
    "                    WHERE Timestamp >= :start_date AND Timestamp <= :end_date\n",
    "                \"\"\")\n",
    "                conn.execute(delete_query, params)\n",
    "                conn.commit()\n",
    "                print(f\"üóëÔ∏è  Success: {result} records deleted.\")\n",
    "            else:\n",
    "                print(\"‚ùå Operation cancelled.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Database Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    delete_range_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7a390a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up existing mock rows...\n",
      "Deleted 0 rows.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DB_SERVER = \"PSQLAPPEG297-01\"\n",
    "DB_NAME = \"Flir\"\n",
    "DB_USER = \"Flir\"\n",
    "DB_PASS = \"Prom@2025\"\n",
    "DB_TABLE = \"ThermalReadings\"\n",
    "\n",
    "CONN_STR = (\n",
    "    f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "    f\"SERVER={DB_SERVER};\"\n",
    "    f\"DATABASE={DB_NAME};\"\n",
    "    f\"UID={DB_USER};\"\n",
    "    f\"PWD={DB_PASS}\"\n",
    ")\n",
    "\n",
    "def delete_mock_data():\n",
    "    try:\n",
    "        conn = pyodbc.connect(CONN_STR)\n",
    "        cursor = conn.cursor()\n",
    "        sql = f\"DELETE FROM {DB_TABLE} WHERE Camera_Serial = 9999\"\n",
    "        print(\"Cleaning up existing mock rows...\")\n",
    "        cursor.execute(sql)\n",
    "        conn.commit()\n",
    "        print(f\"Deleted {cursor.rowcount} rows.\")\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    delete_mock_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7ed064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "üßπ Starting Database Cleanup...\n",
      "üîå Connected to Flir. Running cleanup query on [ThermalReadings]...\n",
      "‚úÖ Success! Rows affected: 29\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote_plus\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- LOAD CONFIGURATION ---\n",
    "load_dotenv()\n",
    "\n",
    "DB_SERVER = os.getenv(\"DB_SERVER\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "\n",
    "# --- THE CLEANUP QUERY ---\n",
    "# We use simple table names here because the connection is already \n",
    "# inside the correct database.\n",
    "cleanup_query = \"\"\"\n",
    "WITH CTE AS (\n",
    "    SELECT \n",
    "        [Timestamp], \n",
    "        [Asset_Name], \n",
    "        [Camera_Serial], \n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY [Timestamp], [Asset_Name], [Camera_Serial] \n",
    "            ORDER BY [Timestamp] DESC\n",
    "        ) AS RowNum\n",
    "    FROM [ThermalReadings]\n",
    ")\n",
    "DELETE FROM CTE WHERE RowNum > 1;\n",
    "\"\"\"\n",
    "\n",
    "def clean_database():\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"üßπ Starting Database Cleanup...\")\n",
    "\n",
    "    if not all([DB_SERVER, DB_NAME, DB_USER, DB_PASS]):\n",
    "        print(\"‚ùå Error: Missing database credentials in .env file.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # 1. Connect to Database\n",
    "        encoded_pass = quote_plus(DB_PASS)\n",
    "        db_url = f\"mssql+pyodbc://{DB_USER}:{encoded_pass}@{DB_SERVER}/{DB_NAME}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "        engine = create_engine(db_url)\n",
    "\n",
    "        # 2. Execute the Delete Query\n",
    "        with engine.connect() as conn:\n",
    "            print(f\"üîå Connected to {DB_NAME}. Running cleanup query on [ThermalReadings]...\")\n",
    "            \n",
    "            # SQLAlchemy requires .commit() for DELETE/UPDATE operations\n",
    "            result = conn.execute(text(cleanup_query))\n",
    "            conn.commit()\n",
    "            \n",
    "            print(f\"‚úÖ Success! Rows affected: {result.rowcount}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during cleanup: {e}\")\n",
    "        \n",
    "        # Fallback: If [ThermalReadings] failed, try [Flir].[ThermalReadings]\n",
    "        if \"Invalid object name\" in str(e):\n",
    "            print(\"\\n‚ö†Ô∏è Retrying with 'Flir' schema...\")\n",
    "            try:\n",
    "                cleanup_query_flir = cleanup_query.replace(\"[ThermalReadings]\", \"[Flir].[ThermalReadings]\")\n",
    "                with engine.connect() as conn:\n",
    "                    result = conn.execute(text(cleanup_query_flir))\n",
    "                    conn.commit()\n",
    "                    print(f\"‚úÖ Success with Flir schema! Rows affected: {result.rowcount}\")\n",
    "            except Exception as e2:\n",
    "                print(f\"‚ùå Failed again: {e2}\")\n",
    "\n",
    "    finally:\n",
    "        if 'engine' in locals():\n",
    "            engine.dispose()\n",
    "        print(\"-------------------------------------------------------\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_database()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
