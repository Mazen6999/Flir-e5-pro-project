{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5715e2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Requirement already satisfied: flyr\n",
      "‚úÖ Requirement already satisfied: pandas\n",
      "‚úÖ Requirement already satisfied: watchdog\n",
      "‚úÖ Requirement already satisfied: matplotlib\n",
      "‚úÖ Requirement already satisfied: sqlalchemy\n",
      "‚úÖ Requirement already satisfied: pyodbc\n",
      "\n",
      "Python dependencies satisfied. ensure 'exiftool-12.35.exe' is in the script directory.\n",
      "Download ODBC Driver 17 for SQL Server to be able to upload: https://go.microsoft.com/fwlink/?linkid=2266337\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip if it's not already installed.\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"‚úÖ Requirement already satisfied: {package}\")\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Installing {package}...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "            print(f\"‚úÖ Successfully installed {package}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå Failed to install {package}. Error: {e}\")\n",
    "            # Exit if a critical package fails to install\n",
    "            sys.exit(1)\n",
    "\n",
    "# List of all required Python packages for the code provided:\n",
    "required_packages = [\n",
    "    'flyr',  # The 'flyr' library\n",
    "    'pandas',\n",
    "    'watchdog',\n",
    "    'matplotlib',\n",
    "    'sqlalchemy',\n",
    "    'pyodbc'          # Driver for MS SQL connectivity\n",
    "]\n",
    "\n",
    "for pkg in required_packages:\n",
    "    install_package(pkg)\n",
    "\n",
    "print(\"\\nPython dependencies satisfied. ensure 'exiftool-12.35.exe' is in the script directory.\")\n",
    "print(\"Download ODBC Driver 17 for SQL Server to be able to upload: https://go.microsoft.com/fwlink/?linkid=2266337\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e258f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### THERMAL DATA EXTRACTOR - MSSQL UPLOAD ####################\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import flyr\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import io\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_FOLDER = \"flir e5 photodump\"\n",
    "EXIFTOOL_PATH = \"exiftool-12.35.exe\" \n",
    "\n",
    "# --- DATABASE CREDENTIALS ---\n",
    "DB_SERVER = \"PSQLAPPEG297-01\"\n",
    "DB_NAME = \"Flir\"\n",
    "DB_USER = \"Flir\"\n",
    "DB_PASS = \"Prom@2025\"\n",
    "DB_TABLE = \"ThermalReadings\"\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def get_db_engine():\n",
    "    encoded_pass = quote_plus(DB_PASS)\n",
    "    db_url = f\"mssql+pyodbc://{DB_USER}:{encoded_pass}@{DB_SERVER}/{DB_NAME}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "    return create_engine(db_url)\n",
    "\n",
    "def get_existing_signatures(engine, start_date_str):\n",
    "    \"\"\"\n",
    "    SMART FILTER: Queries the DB starting exactly from the oldest image in your batch.\n",
    "    start_date_str format: 'YYYY-MM-DD HH:MM:SS'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # We query for anything NEWER than or EQUAL to the oldest image in our folder\n",
    "        query = f\"\"\"\n",
    "            SELECT Asset_Name, Timestamp \n",
    "            FROM {DB_TABLE} \n",
    "            WHERE Timestamp >= '{start_date_str}'\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql(query, engine)\n",
    "        \n",
    "        if not df.empty:\n",
    "            df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='mixed')\n",
    "            signatures = set(zip(\n",
    "                df['Asset_Name'], \n",
    "                df['Timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            ))\n",
    "            return signatures\n",
    "        return set()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Warning: Could not check duplicates (Database might be empty): {e}\")\n",
    "        return set()\n",
    "\n",
    "def get_metadata(folder):\n",
    "    cmd = [\n",
    "        EXIFTOOL_PATH, '-j', '-n', '-r', \n",
    "        '-DateTimeOriginal', \n",
    "        '-CameraSerialNumber', \n",
    "        '-ImageDescription', \n",
    "        '-Emissivity', '-ObjectDistance', '-ext', 'jpg', folder\n",
    "    ]\n",
    "    try:\n",
    "        flags = subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, creationflags=flags)\n",
    "        return json.loads(result.stdout)\n",
    "    except Exception as e:\n",
    "        print(f\"Metadata scan failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_image(filepath, metadata_entry):\n",
    "    filename = os.path.basename(filepath)\n",
    "    asset_name = metadata_entry.get(\"ImageDescription\")\n",
    "    asset_str = str(asset_name).strip() if asset_name else \"\"\n",
    "    \n",
    "    if not asset_str: return None\n",
    "\n",
    "    serial_int = int(metadata_entry[\"CameraSerialNumber\"])\n",
    "    ts_str = str(metadata_entry[\"DateTimeOriginal\"]).replace(\":\", \"-\", 2)\n",
    "\n",
    "    row = {\n",
    "        \"Timestamp\": ts_str, \n",
    "        \"Filename\": filename,\n",
    "        \"Camera_Serial\": serial_int,\n",
    "        \"Asset_Name\": asset_str,     \n",
    "        \"Max_Temp_C\": 0.0, \"Min_Temp_C\": 0.0, \"Center_Temp_C\": 0.0,        \n",
    "        \"Avg_Temp_C\": 0.0, \"Delta_Temp_C\": 0.0, \"Emissivity\": 0.95, \"Distance\": 1.0,             \n",
    "        \"Image_Base64\": \"\"\n",
    "    }\n",
    "\n",
    "    if metadata_entry.get(\"Emissivity\"): row[\"Emissivity\"] = float(metadata_entry[\"Emissivity\"]) \n",
    "    if metadata_entry.get(\"ObjectDistance\"): row[\"Distance\"] = round(float(metadata_entry[\"ObjectDistance\"]), 1)\n",
    "\n",
    "    try:\n",
    "        thermogram = flyr.unpack(filepath)\n",
    "        celsius = thermogram.celsius\n",
    "        \n",
    "        row[\"Max_Temp_C\"] = round(celsius.max(), 1)\n",
    "        row[\"Min_Temp_C\"] = round(celsius.min(), 1)\n",
    "        row[\"Avg_Temp_C\"] = round(celsius.mean(), 1)\n",
    "        row[\"Delta_Temp_C\"] = round(celsius.max() - celsius.min(), 1)\n",
    "        \n",
    "        h, w = celsius.shape\n",
    "        cy, cx = h // 2, w // 2\n",
    "        row[\"Center_Temp_C\"] = round(celsius[cy-1:cy+2, cx-1:cx+2].mean(), 1)\n",
    "\n",
    "        buffer = io.BytesIO()\n",
    "        plt.imsave(buffer, celsius, cmap='inferno', format='jpeg')\n",
    "        buffer.seek(0)\n",
    "        raw_b64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "        row[\"Image_Base64\"] = f\"data:image/jpeg;base64,{raw_b64}\"\n",
    "        buffer.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        return None \n",
    "    return row\n",
    "\n",
    "# --- MAIN ---\n",
    "def main():\n",
    "    if not os.path.exists(INPUT_FOLDER):\n",
    "        print(f\"Folder not found: {INPUT_FOLDER}\")\n",
    "        return\n",
    "\n",
    "    # 1. First, scan Metadata locally to find the time range\n",
    "    print(\"Scanning folder metadata...\")\n",
    "    meta_list = get_metadata(INPUT_FOLDER)\n",
    "    \n",
    "    meta_dict = {}\n",
    "    timestamps = []\n",
    "    \n",
    "    for m in meta_list:\n",
    "        if 'SourceFile' in m:\n",
    "            fname = os.path.basename(m['SourceFile'])\n",
    "            meta_dict[fname] = m\n",
    "            # Collect all valid timestamps\n",
    "            if 'DateTimeOriginal' in m:\n",
    "                # Convert \"YYYY:MM:DD HH:MM:SS\" to \"YYYY-MM-DD HH:MM:SS\"\n",
    "                ts = str(m['DateTimeOriginal']).replace(\":\", \"-\", 2)\n",
    "                timestamps.append(ts)\n",
    "    \n",
    "    if not timestamps:\n",
    "        print(\"No images with timestamps found in folder.\")\n",
    "        return\n",
    "\n",
    "    # 2. Determine the Dynamic Window\n",
    "    # Find the oldest photo in the batch\n",
    "    oldest_photo_time = min(timestamps)\n",
    "    # We strip the time part to query the whole day, just to be safe\n",
    "    query_start_date = oldest_photo_time[:10] + \" 00:00:00\"\n",
    "    \n",
    "    print(f\"Detected oldest image from: {query_start_date}\")\n",
    "    print(f\"Connecting to DB to check records since {query_start_date}...\")\n",
    "\n",
    "    # 3. Connect & Get Duplicates\n",
    "    try:\n",
    "        engine = get_db_engine()\n",
    "        existing_signatures = get_existing_signatures(engine, query_start_date)\n",
    "        print(f\"Database holds {len(existing_signatures)} potential duplicates in this time range.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Connection failed: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 4. Filter New Files\n",
    "    files = [f for f in os.listdir(INPUT_FOLDER) if f.lower().endswith(\".jpg\")]\n",
    "    files_to_process = []\n",
    "    skipped_duplicates = 0\n",
    "    \n",
    "    for f in files:\n",
    "        m_data = meta_dict.get(f, {})\n",
    "        raw_asset = m_data.get(\"ImageDescription\")\n",
    "        raw_time = m_data.get(\"DateTimeOriginal\")\n",
    "        \n",
    "        if raw_asset and raw_time:\n",
    "            asset_key = str(raw_asset).strip()\n",
    "            time_full = str(raw_time).replace(\":\", \"-\", 2)\n",
    "            time_key_simple = time_full[:19] \n",
    "            \n",
    "            if (asset_key, time_key_simple) in existing_signatures:\n",
    "                skipped_duplicates += 1\n",
    "                continue \n",
    "            else:\n",
    "                files_to_process.append(f)\n",
    "        else:\n",
    "            files_to_process.append(f)\n",
    "\n",
    "    if not files_to_process:\n",
    "        print(f\"\\nNo new data found. (Skipped {skipped_duplicates} duplicates).\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(files_to_process)} NEW images to upload...\")\n",
    "\n",
    "    # 5. Process & Upload\n",
    "    new_data_rows = []\n",
    "    for i, f in enumerate(files_to_process):\n",
    "        full_path = os.path.join(INPUT_FOLDER, f)\n",
    "        row = process_image(full_path, meta_dict.get(f, {}))\n",
    "        if row:\n",
    "            new_data_rows.append(row)\n",
    "            print(f\"[{i+1}/{len(files_to_process)}] PROCESSED: {f}\")\n",
    "\n",
    "    if new_data_rows:\n",
    "        cols = [\n",
    "            \"Timestamp\", \"Filename\", \"Camera_Serial\", \"Asset_Name\", \n",
    "            \"Max_Temp_C\", \"Min_Temp_C\", \"Center_Temp_C\", \"Avg_Temp_C\", \"Delta_Temp_C\",\n",
    "            \"Emissivity\", \"Distance\", \"Image_Base64\"\n",
    "        ]\n",
    "        new_df = pd.DataFrame(new_data_rows, columns=cols)\n",
    "        # Ensure timestamp format for SQL\n",
    "        new_df['Timestamp'] = pd.to_datetime(new_df['Timestamp'], format='mixed')\n",
    "\n",
    "        print(f\"Uploading {len(new_df)} rows to table '{DB_TABLE}'...\")\n",
    "        try:\n",
    "            new_df.to_sql(DB_TABLE, engine, if_exists='append', index=False)\n",
    "            print(\"‚úÖ Upload Successful!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Database Upload Failed: {e}\")\n",
    "    else:\n",
    "        print(\"\\nNo valid new images were found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
